{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electric-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-ladder",
   "metadata": {},
   "source": [
    "# Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "assured-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from raw_data\n",
    "X_train = pd.read_csv('../../raw_data/clean_sentiment_data/X_train_.csv')\n",
    "y_train = pd.read_csv('../../raw_data/clean_sentiment_data/y_train_.csv')\n",
    "X_test = pd.read_csv('../../raw_data/clean_sentiment_data/X_test.csv')\n",
    "y_test = pd.read_csv('../../raw_data/clean_sentiment_data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "future-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer.sentiment</th>\n",
       "      <th>Segment_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>245322_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>88797_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.666667</td>\n",
       "      <td>137827_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.333333</td>\n",
       "      <td>3MFNIag0wNE_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3sUS8vXbRwg_14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Answer.sentiment      Segment_ID\n",
       "0          0.333333        245322_6\n",
       "1         -0.333333        88797_12\n",
       "2         -2.666667        137827_6\n",
       "3         -1.333333   3MFNIag0wNE_9\n",
       "4          2.000000  3sUS8vXbRwg_14"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "knowing-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming y in pd.Series\n",
    "y_train = y_train['Answer.sentiment']\n",
    "y_test = y_test['Answer.sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-cherry",
   "metadata": {},
   "source": [
    "# Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-eight",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alike-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = y_train.apply(lambda x: 0 if x <= 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "convenient-humor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But (uhh) so yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The movie ruins it for itself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(umm) The acting's subpar, the screen the scr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And now, because of that, Machinima got intimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I thought something would have to descend on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10837</th>\n",
       "      <td>When we're talking about a verb, a verb can ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10838</th>\n",
       "      <td>If you are continuing at OSU, I hope you have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10839</th>\n",
       "      <td>I come in and I say \"Okay, hi everybody I'm go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10840</th>\n",
       "      <td>This time, in the birthplace of modern innovat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10841</th>\n",
       "      <td>I think Steve Martin's done other better things</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10842 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Phrase\n",
       "0                                      But (uhh) so yeah\n",
       "1                          The movie ruins it for itself\n",
       "2       (umm) The acting's subpar, the screen the scr...\n",
       "3      And now, because of that, Machinima got intimi...\n",
       "4      I thought something would have to descend on m...\n",
       "...                                                  ...\n",
       "10837  When we're talking about a verb, a verb can ha...\n",
       "10838  If you are continuing at OSU, I hope you have ...\n",
       "10839  I come in and I say \"Okay, hi everybody I'm go...\n",
       "10840  This time, in the birthplace of modern innovat...\n",
       "10841    I think Steve Martin's done other better things\n",
       "\n",
       "[10842 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.drop(columns=['Segment_ID', 'clip', 'ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-tablet",
   "metadata": {},
   "source": [
    "## Basic preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-clearing",
   "metadata": {},
   "source": [
    "### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sharp-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(x):\n",
    "    return x.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "great-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['clean_text'] = X_train['Phrase'].apply(lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-specific",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "proud-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def punct(x):\n",
    "    for text in string.punctuation:\n",
    "        x = x.replace(text, '')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "operational-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['clean_text'] = X_train['clean_text'].apply(punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-pharmacy",
   "metadata": {},
   "source": [
    "### Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "stretch-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_num(x):\n",
    "    return ''.join([letter for letter in x if not letter.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "wrong-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['clean_text'] = X_train['clean_text'].apply(del_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-superintendent",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## First model with bag of words CountVectorizer & MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cathedral-colleague",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a validation set on X_train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train_bin, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intense-school",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_t['clean_text'])\n",
    "X_t_vect1 = vectorizer.transform(X_t['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "theoretical-father",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X_t_vect1, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "quiet-record",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vectorizer on X_val\n",
    "X_val_vect1 = vectorizer.transform(X_val['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cubic-victim",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute accuracy on validation set\n",
    "round(nb_model.score(X_val_vect1, y_val),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "junior-illinois",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred1 = nb_model.predict(X_val_vect1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "needed-friendship",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix1 = confusion_matrix(y_val, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rotary-jaguar",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(matrix1, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-structure",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exploration of predicts from model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "existing-likelihood",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = nb_model.predict(X_val_vect1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "lucky-inquiry",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = X_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "whole-saver",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results['y_val'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "developed-celebration",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results['y_pred'] = y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "accepting-waterproof",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = results.drop(columns=['clip', 'ID', 'Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unknown-olive",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results['results'] = 1 - abs(results['y_val'] - results['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "composed-jason",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2169, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "angry-gateway",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tete_faux = results[results['results'] == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "soviet-peoples",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tete_faux.to_csv('False_nlp_ml_m1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-animal",
   "metadata": {},
   "source": [
    "## Tf-Id vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "chronic-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a pipeline a grid search to know which parameters are better \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('model', MultinomialNB ())\n",
    "])\n",
    "\n",
    "grid_params = {'vect__max_df': [0.7, 0.8, 0.9],\n",
    "              'vect__max_features': [30, 40, 50, 60],\n",
    "              'vect__ngram_range': [(1,1), (2,2)],\n",
    "              'vect__min_df': [0.8, 0.9, 1]}\n",
    "\n",
    "search = GridSearchCV(pipe, grid_params, n_jobs=-1, verbose=1, scoring='accuracy',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "lesser-exhaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b9a90a6cb624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    682\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    685\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search.fit(X_t['clean_text'], y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_good = Pipeline([\n",
    "    ('vect', TfidfVectorizer(max_df = 0.7, max_features = 50, ngram_range = (1,1))),\n",
    "    ('model', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_good.fit(X_t['clean_text'], y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pipe_good.score(X_val['clean_text'], y_val),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = pipe_good.predict(X_val['clean_text'])\n",
    "matrix2 = confusion_matrix(y_val, y_pred2)\n",
    "sns.heatmap(matrix2, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-pottery",
   "metadata": {},
   "source": [
    "## Test previous models with more preprocessing: stopwords + lemmising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-richards",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "stretch-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def rem_stop(x):\n",
    "    word_tokens = word_tokenize(x)\n",
    "    return ' '.join([word for word in word_tokens if word not in stop_words])\n",
    "X_train['clean_text2'] = X_train['clean_text'].apply(rem_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "wooden-texture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment_ID</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>clip</th>\n",
       "      <th>ID</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245322_6</td>\n",
       "      <td>But (uhh) so yeah</td>\n",
       "      <td>6</td>\n",
       "      <td>245322</td>\n",
       "      <td>but uhh so yeah</td>\n",
       "      <td>uhh yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88797_12</td>\n",
       "      <td>The movie ruins it for itself</td>\n",
       "      <td>12</td>\n",
       "      <td>88797</td>\n",
       "      <td>the movie ruins it for itself</td>\n",
       "      <td>movie ruins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137827_6</td>\n",
       "      <td>(umm) The acting's subpar, the screen the scr...</td>\n",
       "      <td>6</td>\n",
       "      <td>137827</td>\n",
       "      <td>umm the actings subpar the screen the screenp...</td>\n",
       "      <td>umm actings subpar screen screenplay stutter d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3MFNIag0wNE_9</td>\n",
       "      <td>And now, because of that, Machinima got intimi...</td>\n",
       "      <td>9</td>\n",
       "      <td>3MFNIag0wNE</td>\n",
       "      <td>and now because of that machinima got intimida...</td>\n",
       "      <td>machinima got intimidated decided shut show en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3sUS8vXbRwg_14</td>\n",
       "      <td>I thought something would have to descend on m...</td>\n",
       "      <td>14</td>\n",
       "      <td>3sUS8vXbRwg</td>\n",
       "      <td>i thought something would have to descend on m...</td>\n",
       "      <td>thought something would descend would level pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fz-MzQcOBwQ_12</td>\n",
       "      <td>I don't say this lightly but this is probably...</td>\n",
       "      <td>12</td>\n",
       "      <td>fz-MzQcOBwQ</td>\n",
       "      <td>i dont say this lightly but this is probably ...</td>\n",
       "      <td>dont say lightly probably one best books ever ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>106941_2</td>\n",
       "      <td>Surely, surely (stutter) wasn't hostile</td>\n",
       "      <td>2</td>\n",
       "      <td>106941</td>\n",
       "      <td>surely surely stutter wasnt hostile</td>\n",
       "      <td>surely surely stutter wasnt hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kpe5fISxRTg_6</td>\n",
       "      <td>Basically you're going to want to increase flu...</td>\n",
       "      <td>6</td>\n",
       "      <td>Kpe5fISxRTg</td>\n",
       "      <td>basically youre going to want to increase flui...</td>\n",
       "      <td>basically youre going want increase fluids res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67uKYi7mslE_14</td>\n",
       "      <td>That topic has come up before so thatâ€™s somet...</td>\n",
       "      <td>14</td>\n",
       "      <td>67uKYi7mslE</td>\n",
       "      <td>that topic has come up before so thatâ€™s somet...</td>\n",
       "      <td>topic come â€™ something â€™ looking maybe somethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>180923_11</td>\n",
       "      <td>I found this film to be one of the worst Disn...</td>\n",
       "      <td>11</td>\n",
       "      <td>180923</td>\n",
       "      <td>i found this film to be one of the worst disn...</td>\n",
       "      <td>found film one worst disney movies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Segment_ID                                             Phrase  clip  \\\n",
       "0        245322_6                                  But (uhh) so yeah     6   \n",
       "1        88797_12                      The movie ruins it for itself    12   \n",
       "2        137827_6   (umm) The acting's subpar, the screen the scr...     6   \n",
       "3   3MFNIag0wNE_9  And now, because of that, Machinima got intimi...     9   \n",
       "4  3sUS8vXbRwg_14  I thought something would have to descend on m...    14   \n",
       "5  fz-MzQcOBwQ_12   I don't say this lightly but this is probably...    12   \n",
       "6        106941_2            Surely, surely (stutter) wasn't hostile     2   \n",
       "7   Kpe5fISxRTg_6  Basically you're going to want to increase flu...     6   \n",
       "8  67uKYi7mslE_14   That topic has come up before so thatâ€™s somet...    14   \n",
       "9       180923_11   I found this film to be one of the worst Disn...    11   \n",
       "\n",
       "            ID                                         clean_text  \\\n",
       "0       245322                                    but uhh so yeah   \n",
       "1        88797                      the movie ruins it for itself   \n",
       "2       137827   umm the actings subpar the screen the screenp...   \n",
       "3  3MFNIag0wNE  and now because of that machinima got intimida...   \n",
       "4  3sUS8vXbRwg  i thought something would have to descend on m...   \n",
       "5  fz-MzQcOBwQ   i dont say this lightly but this is probably ...   \n",
       "6       106941                surely surely stutter wasnt hostile   \n",
       "7  Kpe5fISxRTg  basically youre going to want to increase flui...   \n",
       "8  67uKYi7mslE   that topic has come up before so thatâ€™s somet...   \n",
       "9       180923   i found this film to be one of the worst disn...   \n",
       "\n",
       "                                         clean_text2  \n",
       "0                                           uhh yeah  \n",
       "1                                        movie ruins  \n",
       "2  umm actings subpar screen screenplay stutter d...  \n",
       "3  machinima got intimidated decided shut show en...  \n",
       "4  thought something would descend would level pu...  \n",
       "5  dont say lightly probably one best books ever ...  \n",
       "6                surely surely stutter wasnt hostile  \n",
       "7  basically youre going want increase fluids res...  \n",
       "8  topic come â€™ something â€™ looking maybe somethi...  \n",
       "9                 found film one worst disney movies  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-powder",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "pursuant-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(x):\n",
    "    a = x.split(' ')\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in a]\n",
    "    return ' '.join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "accepting-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['clean_text2'] = X_train['clean_text2'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "green-negotiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment_ID</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>clip</th>\n",
       "      <th>ID</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245322_6</td>\n",
       "      <td>But (uhh) so yeah</td>\n",
       "      <td>6</td>\n",
       "      <td>245322</td>\n",
       "      <td>but uhh so yeah</td>\n",
       "      <td>uhh yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88797_12</td>\n",
       "      <td>The movie ruins it for itself</td>\n",
       "      <td>12</td>\n",
       "      <td>88797</td>\n",
       "      <td>the movie ruins it for itself</td>\n",
       "      <td>movie ruin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137827_6</td>\n",
       "      <td>(umm) The acting's subpar, the screen the scr...</td>\n",
       "      <td>6</td>\n",
       "      <td>137827</td>\n",
       "      <td>umm the actings subpar the screen the screenp...</td>\n",
       "      <td>umm acting subpar screen screenplay stutter di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3MFNIag0wNE_9</td>\n",
       "      <td>And now, because of that, Machinima got intimi...</td>\n",
       "      <td>9</td>\n",
       "      <td>3MFNIag0wNE</td>\n",
       "      <td>and now because of that machinima got intimida...</td>\n",
       "      <td>machinima got intimidated decided shut show en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3sUS8vXbRwg_14</td>\n",
       "      <td>I thought something would have to descend on m...</td>\n",
       "      <td>14</td>\n",
       "      <td>3sUS8vXbRwg</td>\n",
       "      <td>i thought something would have to descend on m...</td>\n",
       "      <td>thought something would descend would level pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fz-MzQcOBwQ_12</td>\n",
       "      <td>I don't say this lightly but this is probably...</td>\n",
       "      <td>12</td>\n",
       "      <td>fz-MzQcOBwQ</td>\n",
       "      <td>i dont say this lightly but this is probably ...</td>\n",
       "      <td>dont say lightly probably one best book ever read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>106941_2</td>\n",
       "      <td>Surely, surely (stutter) wasn't hostile</td>\n",
       "      <td>2</td>\n",
       "      <td>106941</td>\n",
       "      <td>surely surely stutter wasnt hostile</td>\n",
       "      <td>surely surely stutter wasnt hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kpe5fISxRTg_6</td>\n",
       "      <td>Basically you're going to want to increase flu...</td>\n",
       "      <td>6</td>\n",
       "      <td>Kpe5fISxRTg</td>\n",
       "      <td>basically youre going to want to increase flui...</td>\n",
       "      <td>basically youre going want increase fluid rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67uKYi7mslE_14</td>\n",
       "      <td>That topic has come up before so thatâ€™s somet...</td>\n",
       "      <td>14</td>\n",
       "      <td>67uKYi7mslE</td>\n",
       "      <td>that topic has come up before so thatâ€™s somet...</td>\n",
       "      <td>topic come â€™ something â€™ looking maybe somethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>180923_11</td>\n",
       "      <td>I found this film to be one of the worst Disn...</td>\n",
       "      <td>11</td>\n",
       "      <td>180923</td>\n",
       "      <td>i found this film to be one of the worst disn...</td>\n",
       "      <td>found film one worst disney movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Segment_ID                                             Phrase  clip  \\\n",
       "0        245322_6                                  But (uhh) so yeah     6   \n",
       "1        88797_12                      The movie ruins it for itself    12   \n",
       "2        137827_6   (umm) The acting's subpar, the screen the scr...     6   \n",
       "3   3MFNIag0wNE_9  And now, because of that, Machinima got intimi...     9   \n",
       "4  3sUS8vXbRwg_14  I thought something would have to descend on m...    14   \n",
       "5  fz-MzQcOBwQ_12   I don't say this lightly but this is probably...    12   \n",
       "6        106941_2            Surely, surely (stutter) wasn't hostile     2   \n",
       "7   Kpe5fISxRTg_6  Basically you're going to want to increase flu...     6   \n",
       "8  67uKYi7mslE_14   That topic has come up before so thatâ€™s somet...    14   \n",
       "9       180923_11   I found this film to be one of the worst Disn...    11   \n",
       "\n",
       "            ID                                         clean_text  \\\n",
       "0       245322                                    but uhh so yeah   \n",
       "1        88797                      the movie ruins it for itself   \n",
       "2       137827   umm the actings subpar the screen the screenp...   \n",
       "3  3MFNIag0wNE  and now because of that machinima got intimida...   \n",
       "4  3sUS8vXbRwg  i thought something would have to descend on m...   \n",
       "5  fz-MzQcOBwQ   i dont say this lightly but this is probably ...   \n",
       "6       106941                surely surely stutter wasnt hostile   \n",
       "7  Kpe5fISxRTg  basically youre going to want to increase flui...   \n",
       "8  67uKYi7mslE   that topic has come up before so thatâ€™s somet...   \n",
       "9       180923   i found this film to be one of the worst disn...   \n",
       "\n",
       "                                         clean_text2  \n",
       "0                                           uhh yeah  \n",
       "1                                         movie ruin  \n",
       "2  umm acting subpar screen screenplay stutter di...  \n",
       "3  machinima got intimidated decided shut show en...  \n",
       "4  thought something would descend would level pu...  \n",
       "5  dont say lightly probably one best book ever read  \n",
       "6                surely surely stutter wasnt hostile  \n",
       "7  basically youre going want increase fluid rest...  \n",
       "8  topic come â€™ something â€™ looking maybe somethi...  \n",
       "9                  found film one worst disney movie  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-skirt",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Testing model on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-mercury",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a validation set on X_train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train_bin, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-constitutional",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_t['clean_text2'])\n",
    "X_t_vect2 = vectorizer.transform(X_t['clean_text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-perth",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nb_model2 = MultinomialNB()\n",
    "\n",
    "nb_model2.fit(X_t_vect2, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-directive",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vectorizer on X_val\n",
    "X_val_vect2 = vectorizer.transform(X_val['clean_text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-damage",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compute accuracy on validation set\n",
    "round(nb_model2.score(X_val_vect2, y_val),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-meeting",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred2 = nb_model2.predict(X_val_vect2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-robinson",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matrix3 = confusion_matrix(y_val, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-exhibit",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(matrix3, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-fossil",
   "metadata": {},
   "source": [
    "# 3-dim classification -0.5, 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-demographic",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create 3 classes: -1 if neg, 0 if neutral, 1 if positive. We settle netral btw -0.5 & 0.5\n",
    "\n",
    "def first_split(x):\n",
    "    if x < -0.5:\n",
    "        return -1\n",
    "    if x < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_class3 = y_train.apply(first_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes appear to be relatively balanced with this split\n",
    "sns.histplot(y_train_class3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-captain",
   "metadata": {},
   "source": [
    "## First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_class3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation set on X_train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train_class3, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_t['clean_text'])\n",
    "X_t_vect3 = vectorizer.transform(X_t['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model3 = MultinomialNB()\n",
    "nb_model3.fit(X_t_vect3, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vect3 = vectorizer.transform(X_val['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(nb_model3.score(X_val_vect3, y_val),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = nb_model3.predict(X_val_vect3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix3 = confusion_matrix(y_val, y_pred3, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(matrix3, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-burst",
   "metadata": {},
   "source": [
    "## CountVectorizer grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation set on X_train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train_class3, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('model', MultinomialNB ())\n",
    "])\n",
    "\n",
    "grid_params = {'vect__max_df': [0.4, 0.5],\n",
    "              'vect__max_features': [9000, 10000, 11000]}\n",
    "\n",
    "search = GridSearchCV(pipe, grid_params, n_jobs=-1, verbose=1, scoring='accuracy',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_t['clean_text'], y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_good = Pipeline([\n",
    "    ('vect', TfidfVectorizer(max_df = 0.5, max_features = 10000, min_df= 1)),\n",
    "    ('model', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_good.fit(X_t['clean_text'], y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pipe_good.score(X_val['clean_text'], y_val),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-cologne",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## With more processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-vegetation",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a validation set on X_train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train_class3, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-quarter",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_t['clean_text2'])\n",
    "X_t_vect2 = vectorizer.transform(X_t['clean_text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-shoot",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nb_model4 = MultinomialNB()\n",
    "\n",
    "nb_model4.fit(X_t_vect2, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-pointer",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val_vect4 = vectorizer.transform(X_val['clean_text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-disney",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "round(nb_model4.score(X_val_vect4, y_val),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-making",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred4 = nb_model4.predict(X_val_vect4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-siemens",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matrix4 = confusion_matrix(y_val, y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-temple",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(matrix4, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-contributor",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-whole",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-hydrogen",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-account",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wiki = TextBlob(\"I am in love\", analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-scanner",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wiki.sentiment.p_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-infrastructure",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def text_blob(x):\n",
    "    return TextBlob(x, analyzer=NaiveBayesAnalyzer()).sentiment.p_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-transfer",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-pearl",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_sample= X_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-socket",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fun_textblob(x):\n",
    "    return 1 if x > 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-persian",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "blob_pred = X_train['textblob'].apply(fun_textblob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-convert",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3-dim -1 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-shape",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-eligibility",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's create 3 classes: -1 if neg, 0 if neutral, 1 if positive. We settle netral btw -1 & 1\n",
    "\n",
    "def first_split(x):\n",
    "    if x < -1:\n",
    "        return -1\n",
    "    if x < 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-winning",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train_class3_bis = y_train.apply(first_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-writing",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-adventure",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['textblob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-therapy",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = X_train.copy()\n",
    "df['y'] = y_train_class3_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-adaptation",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Classes appear to be relatively balanced with this split\n",
    "sns.histplot(df['y']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-intelligence",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_majority = df[df['y'] == 0]\n",
    "df_minority = df[df['y'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-memorial",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=2500) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-option",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_majority_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-chocolate",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_minority.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-wrapping",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-service",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-diamond",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_bal = df_downsampled.drop(columns=['y'])\n",
    "y_bal = df_downsampled['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-german",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_t_bal, X_val_bal, y_t_bal, y_val_bal = train_test_split(X_bal, y_bal, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-grenada",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_t_bal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-method",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_t_bal['clean_text'])\n",
    "X_t_vect5 = vectorizer.transform(X_t_bal['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-seafood",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nb_model5 = MultinomialNB()\n",
    "nb_model5.fit(X_t_vect5, y_t_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-plenty",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val_vect5 = vectorizer.transform(X_val_bal['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-purple",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "round(nb_model5.score(X_val_vect5, y_val_bal),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-treat",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred5 = nb_model5.predict(X_val_vect5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-turtle",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matrix5 = confusion_matrix(y_val_bal, y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-knock",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(matrix5, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-wilderness",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_downsampled.shape, y_pred5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-shoot",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-meaning",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val_bal.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-swing",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results2 = X_val_bal.copy()\n",
    "results2['y'] = y_val_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-membrane",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results2['y_pred'] = y_pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-output",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-argentina",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results2[\"confusion\"] = abs(results2[\"y\"] - results2[\"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-gauge",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-child",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results_wrong = results2[results2['confusion'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-empire",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results_wrong.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-conversion",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_wrong = results_wrong.sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-milan",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "blob = TextBlob(\"I love this library\", analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment.p_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-democrat",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def blob(x):\n",
    "    blob = TextBlob(x, analyzer=NaiveBayesAnalyzer())\n",
    "    if blob.sentiment.p_pos < 0.4:\n",
    "        return -1\n",
    "    elif blob.sentiment.p_pos < 0.6:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-greece",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_wrong['blob'] = sample_wrong['Phrase'].apply(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-gather",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_wrong.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-boost",
   "metadata": {},
   "source": [
    "# Regression grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "accompanied-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline_reg = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('model', Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "necessary-mobility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=None, vocabulary=None)),\n",
       "  ('model',\n",
       "   Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "         normalize=False, random_state=None, solver='auto', tol=0.001))],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, vocabulary=None),\n",
       " 'model': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "       normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': None,\n",
       " 'vect__vocabulary': None,\n",
       " 'model__alpha': 1.0,\n",
       " 'model__copy_X': True,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__max_iter': None,\n",
       " 'model__normalize': False,\n",
       " 'model__random_state': None,\n",
       " 'model__solver': 'auto',\n",
       " 'model__tol': 0.001}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "tropical-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {'vect__max_df': [0.4, 0.5, 0.6],\n",
    "              'vect__max_features': [9000, 10000, 11000],\n",
    "              'vect__ngram_range': [(1, 1), (1,2), (1,3)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "judicial-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipeline_reg, grid_params, n_jobs=-1, verbose=1, scoring='r2',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "directed-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "incident-portal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:   56.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)...\n",
       "                                        Ridge(alpha=1.0, copy_X=True,\n",
       "                                              fit_intercept=True, max_iter=None,\n",
       "                                              normalize=False,\n",
       "                                              random_state=None, solver='auto',\n",
       "                                              tol=0.001))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'vect__max_df': [0.4, 0.5, 0.6],\n",
       "                         'vect__max_features': [9000, 10000, 11000],\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_t['clean_text'], y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "sexual-treasurer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__max_df': 0.4, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "smart-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_reg_good = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=0.5, max_features=10000, ngram_range=(1, 1))),\n",
    "    ('model', Ridge(alpha=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "headed-subscriber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.5,\n",
       "                                 max_features=10000, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('model',\n",
       "                 Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "                       normalize=False, random_state=None, solver='auto',\n",
       "                       tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_reg_good.fit(X_train['clean_text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "attractive-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg = pipe_reg_good.predict(X_test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "detailed-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_reg = mean_absolute_error(y_test,  y_pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "intelligent-daniel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Regression = 0.84\n"
     ]
    }
   ],
   "source": [
    "print(f'MAE Regression = {round(mae_reg, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-stretch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
